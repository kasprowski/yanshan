{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transforming a number into text\n",
    "- input: number in range(0,DATASE_SIZE)\n",
    "- output: text\n",
    "\n",
    "Examples: \n",
    "- input: 234, output: two hundred thirty four\n",
    "- input: 6, output: six\n",
    "\n",
    "The code in file number2words.py taken from: https://www.codesansar.com/python-programming-examples/number-words-conversion-no-library-used.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector\n",
    "import numpy as np\n",
    "from number2words import getWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 30, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           74240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 26)            3354      \n",
      "=================================================================\n",
      "Total params: 340,794\n",
      "Trainable params: 340,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_SEQUENCE_LEN=30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1) ) \n",
    "model.add(RepeatVector(OUTPUT_SEQUENCE_LEN)) #length of the text\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy','mae'])\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (input): 5\n",
      "Label ['f', 'i', 'v', 'e', ' ', ' ']\n",
      "Label encoded (output):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "(200, 30, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-64cf8ab9d612>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=200\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    samples.append(i)\n",
    "    #words = lslownie(i)\n",
    "    words = getWords(i)\n",
    "    labels.append(list(words))\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Sample (input):\",samples[5])\n",
    "print(\"Label\",labels[5])\n",
    "\n",
    "codes = ' abcdefghijklmnoprstuvwxyz'\n",
    "\n",
    "nlabels = np.zeros((DATASET_SIZE,OUTPUT_SEQUENCE_LEN,len(codes)))\n",
    "for i in range(DATASET_SIZE):\n",
    "    for j in range(OUTPUT_SEQUENCE_LEN):\n",
    "        if j>=len(labels[i]): \n",
    "                nlabels[i][j][0]=1\n",
    "                continue\n",
    "        x = labels[i][j]\n",
    "        #print(x)\n",
    "        index = codes.index(x)\n",
    "        nlabels[i][j][index] = 1\n",
    "print(\"Label encoded (output):\\n\",nlabels[123])\n",
    "labels = nlabels\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100  test samples 100\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = .5\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels,train_size=TRAINING_SIZE)\n",
    "print('Training samples:',len(trainSamples),' test samples',len(testSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 samples 50 epochs and batch_size= 50\n",
      "Epochs so far 50\n",
      "\n",
      "Epoch 100 - loss = 0.959, loss improvement = 0.263\n",
      "80 -> one yyy\n",
      "195 -> nne hundred  ittyyy\n",
      "182 -> nne hundred  ittyyy\n",
      "178 -> nne hundred  ittyyy\n",
      "40 -> oittty  e\n",
      "37 -> oittty  ee\n",
      "2 -> ooe\n",
      "21 -> oitttt\n",
      "146 -> nne hundrdd  ittyy\n",
      "155 -> nne hundred  ittyy\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 150 - loss = 0.761, loss improvement = 0.191\n",
      "103 -> one hundred  iee\n",
      "163 -> one hundred  ietyy  oe\n",
      "10 -> oiiee\n",
      "132 -> one hundred fietty  ee\n",
      "158 -> one hundred  ietyy  oe\n",
      "132 -> one hundred fietty  ee\n",
      "199 -> one hundred  iitty  oe\n",
      "8 -> oiee\n",
      "3 -> ooe\n",
      "78 -> onetty  iee\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 200 - loss = 0.615, loss improvement = 0.146\n",
      "106 -> one hundred  iee\n",
      "164 -> one hundred siety  oee\n",
      "84 -> oieety  ie\n",
      "147 -> one hundred fitty  iee\n",
      "1 -> ooo\n",
      "31 -> oirtty  ie\n",
      "85 -> oieety  ie\n",
      "97 -> oneety  iee\n",
      "133 -> one hundred tietty  ie\n",
      "193 -> one hundred sieety\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 250 - loss = 0.554, loss improvement = 0.070\n",
      "12 -> tieee\n",
      "140 -> one hundred firty  ive\n",
      "69 -> oixtyy oive\n",
      "51 -> oirty  iee\n",
      "77 -> oigety  one\n",
      "123 -> one hundred tiitty  ie\n",
      "147 -> one hundred firty five\n",
      "12 -> tieee\n",
      "126 -> one hundred tiirty  ie\n",
      "3 -> tioe\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 300 - loss = 0.443, loss improvement = 0.107\n",
      "131 -> one hundred twirty sive\n",
      "35 -> tiirty five\n",
      "188 -> one hundred sigety  oe\n",
      "190 -> one hundred eigety  oe\n",
      "161 -> one hundred sixty five\n",
      "158 -> one hundred fifty sive\n",
      "62 -> oixty five\n",
      "121 -> one hundred tietty\n",
      "74 -> oixety  oive\n",
      "88 -> oinety  oe\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 350 - loss = 0.447, loss improvement =-0.002\n",
      "66 -> oixty five\n",
      "105 -> one hundred  ive\n",
      "184 -> one hundred sigety  oo\n",
      "117 -> one hundred tieeeen\n",
      "90 -> oinety  ne\n",
      "62 -> fixty five\n",
      "137 -> one hundred thirty sive\n",
      "15 -> tieteen\n",
      "160 -> one hundred sixty sive\n",
      "78 -> oigety  oie\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 400 - loss = 0.393, loss improvement = 0.024\n",
      "37 -> thirty five\n",
      "93 -> oinety  iee\n",
      "72 -> sixtyyffive\n",
      "113 -> one hundred eieee\n",
      "173 -> one hundred sivey\n",
      "7 -> tine\n",
      "11 -> tinht\n",
      "108 -> one hundred five\n",
      "46 -> forty  i e\n",
      "28 -> twinty fine\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 450 - loss = 0.313, loss improvement = 0.066\n",
      "24 -> twenty three\n",
      "40 -> forty  n\n",
      "33 -> thirty fin\n",
      "194 -> one hundred einety twre\n",
      "52 -> fifty five\n",
      "139 -> one hundred thrty toee\n",
      "38 -> thirty sive\n",
      "119 -> one hundred tiente n\n",
      "147 -> one hundred forty fiv\n",
      "30 -> thinty nin\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 500 - loss = 0.284, loss improvement = 0.028\n",
      "88 -> oinety tnn\n",
      "70 -> sixtny five\n",
      "15 -> tifteen\n",
      "23 -> twenty three\n",
      "190 -> one hundred eigety tire\n",
      "163 -> one hundred sixty five\n",
      "114 -> one hundred eieeeen\n",
      "65 -> sixty five\n",
      "175 -> one hundred sigeny\n",
      "139 -> one hundred forty toee\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 550 - loss = 0.290, loss improvement =-0.006\n",
      "19 -> tientye\n",
      "48 -> forty nige\n",
      "160 -> one hundred fifty five\n",
      "77 -> siventy five\n",
      "189 -> one hundred eighty tne\n",
      "7 -> tinh\n",
      "18 -> tietteen\n",
      "136 -> one hundred thirty sixe\n",
      "155 -> one hundred fifty five\n",
      "90 -> oinety nnn\n",
      "Correct 0 of 200  =  0.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "BATCH_SIZE = int(len(trainSamples)/2)\n",
    "print('Training with',len(trainSamples),'samples',EPOCHS,'epochs and batch_size=',BATCH_SIZE)\n",
    "print(\"Epochs so far\",num_epochs)\n",
    "for x in range(10):\n",
    "    H = model.fit(trainSamples, trainLabels, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE)\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    print(\"Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\".\n",
    "          format(num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    c,l,p = check_model()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> trro  [T]\n",
      "1 -> two  \n",
      "2 -> two  [T]\n",
      "3 -> three  [T]\n",
      "4 -> three  \n",
      "5 -> tige  \n",
      "6 -> tige  \n",
      "7 -> tinh  \n",
      "8 -> tinh  [T]\n",
      "9 -> tin  [T]\n",
      "10 -> tin  [T]\n",
      "11 -> tinh  \n",
      "12 -> tinrt  \n",
      "13 -> tinrteen  [T]\n",
      "14 -> tifteenn  \n",
      "15 -> tifteen  [T]\n",
      "16 -> tigteen  [T]\n",
      "17 -> tigttenn  \n",
      "18 -> tietteen  [T]\n",
      "19 -> tientye  \n",
      "20 -> twenty  [T]\n",
      "21 -> twenty  he  \n",
      "22 -> twenty three  \n",
      "23 -> twenty three  [T]\n",
      "24 -> twenty sire  \n",
      "25 -> twenty six  \n",
      "26 -> twenty six  [T]\n",
      "27 -> twenty six  \n",
      "28 -> twenty nin  \n",
      "29 -> twenty nin  [T]\n",
      "30 -> thinty nnn  \n",
      "31 -> thirty nnn  [T]\n",
      "32 -> thirty nin  \n",
      "33 -> thirty fiu  \n",
      "34 -> thirty fiur  [T]\n",
      "35 -> thirty five  [T]\n",
      "36 -> thirty five  \n",
      "37 -> thirty siven  [T]\n",
      "38 -> fhrrty eivht  [T]\n",
      "39 -> forty  \n",
      "40 -> forty  [T]\n",
      "41 -> forty  [T]\n",
      "42 -> forty  i  \n",
      "43 -> forty oige  [T]\n",
      "44 -> forty oige  \n",
      "45 -> forty nige  [T]\n",
      "46 -> forty nige  [T]\n",
      "47 -> forty nige  \n",
      "48 -> forty nige  [T]\n",
      "49 -> forty nige  [T]\n",
      "50 -> fofty nige  [T]\n",
      "51 -> fifty nige  [T]\n",
      "52 -> fifty nige  \n",
      "53 -> fifty nige  [T]\n",
      "54 -> fifty nige  \n",
      "55 -> fifty tire  [T]\n",
      "56 -> fifty tire  \n",
      "57 -> fifty tire  \n",
      "58 -> fifty tire  [T]\n",
      "59 -> fifty tire  [T]\n",
      "60 -> fifty fire  \n",
      "61 -> sifty fire  \n",
      "62 -> sixty fire  \n",
      "63 -> sixty fire  [T]\n",
      "64 -> sixty five  [T]\n",
      "65 -> sixty five  [T]\n",
      "66 -> sixty five  [T]\n",
      "67 -> sixty five  [T]\n",
      "68 -> sixty five  \n",
      "69 -> sixty five  \n",
      "70 -> sixtn  five  \n",
      "71 -> sixent five  \n",
      "72 -> siventy five  \n",
      "73 -> siventy five  \n",
      "74 -> siventy five  [T]\n",
      "75 -> siventy five  [T]\n",
      "76 -> siventy five  \n",
      "77 -> siventy five  [T]\n",
      "78 -> siventy five  \n",
      "79 -> siventy niv  [T]\n",
      "80 -> sivett  nir  \n",
      "81 -> sigety  no  [T]\n",
      "82 -> sighty fne  [T]\n",
      "83 -> sighty fne  \n",
      "84 -> sighty fnn  [T]\n",
      "85 -> sighty fnn  \n",
      "86 -> nighty onn  \n",
      "87 -> nighty onn  \n",
      "88 -> nighty nnn  \n",
      "89 -> ninety nnn  [T]\n",
      "90 -> oinety nnn  [T]\n",
      "91 -> oinety nn  [T]\n",
      "92 -> oinety tnr  \n",
      "93 -> oinety tnre  [T]\n",
      "94 -> oinety tire  \n",
      "95 -> oinety sive  [T]\n",
      "96 -> oinety sive  [T]\n",
      "97 -> oinety sive  [T]\n",
      "98 -> onnety sive  [T]\n",
      "99 -> onnety sieh  \n",
      "100 -> one hundred  [T]\n",
      "101 -> one hundred  [T]\n",
      "102 -> one hundred  [T]\n",
      "103 -> one hundred foe  \n",
      "104 -> one hundred fove  [T]\n",
      "105 -> one hundred five  [T]\n",
      "106 -> one hundred five  \n",
      "107 -> one hundred five  [T]\n",
      "108 -> one hundred sive  \n",
      "109 -> one hundred sive  [T]\n",
      "110 -> one hundred sivee  \n",
      "111 -> one hundred eivee  [T]\n",
      "112 -> one hundred eieeen  \n",
      "113 -> one hundred eieeee  \n",
      "114 -> one hundred sieeeen  \n",
      "115 -> one hundred sieeeen  \n",
      "116 -> one hundred sieeten  [T]\n",
      "117 -> one hundred sieete  \n",
      "118 -> one hundred tienteen  [T]\n",
      "119 -> one hundred tienteen  [T]\n",
      "120 -> one hundred twentyen  [T]\n",
      "121 -> one hundred twentyen  [T]\n",
      "122 -> one hundred twenty n  \n",
      "123 -> one hundred twenty nie  \n",
      "124 -> one hundred twenty siv  \n",
      "125 -> one hundred twenty siv  [T]\n",
      "126 -> one hundred twenty six  [T]\n",
      "127 -> one hundred twenty sixe  \n",
      "128 -> one hundred twenty sixe  \n",
      "129 -> one hundred twenty sixe  \n",
      "130 -> one hundred twinty sixe  \n",
      "131 -> one hundred twinty sixe  \n",
      "132 -> one hundred thirty sixe  [T]\n",
      "133 -> one hundred thirty sixe  \n",
      "134 -> one hundred thirty sixe  \n",
      "135 -> one hundred thirty sixe  [T]\n",
      "136 -> one hundred thirty sixe  [T]\n",
      "137 -> one hundred thirty sive  [T]\n",
      "138 -> one hundred thirty sive  \n",
      "139 -> one hundred thirty sive  \n",
      "140 -> one hundred thirty sive  \n",
      "141 -> one hundred forrt tnee  [T]\n",
      "142 -> one hundred forty tnee  [T]\n",
      "143 -> one hundred forty tiee  [T]\n",
      "144 -> one hundred forty tiee  \n",
      "145 -> one hundred forty tiee  [T]\n",
      "146 -> one hundred forty tire  \n",
      "147 -> one hundred forty fire  \n",
      "148 -> one hundred forty fire  [T]\n",
      "149 -> one hundred forty five  \n",
      "150 -> one hundred forty five  \n",
      "151 -> one hundred forty five  [T]\n",
      "152 -> one hundred fofty five  \n",
      "153 -> one hundred fifty five  \n",
      "154 -> one hundred fifty five  [T]\n",
      "155 -> one hundred fifty five  [T]\n",
      "156 -> one hundred fifty five  [T]\n",
      "157 -> one hundred fifty five  [T]\n",
      "158 -> one hundred fifty five  \n",
      "159 -> one hundred fifty five  [T]\n",
      "160 -> one hundred fifty five  \n",
      "161 -> one hundred fifty five  [T]\n",
      "162 -> one hundred fifty five  [T]\n",
      "163 -> one hundred sixty five  [T]\n",
      "164 -> one hundred sixty five  [T]\n",
      "165 -> one hundred sixty five  [T]\n",
      "166 -> one hundred sixty five  \n",
      "167 -> one hundred sixty five  [T]\n",
      "168 -> one hundred sixty five  \n",
      "169 -> one hundred sixty fiee  \n",
      "170 -> one hundred sixty fnee  [T]\n",
      "171 -> one hundred sixty fnee  [T]\n",
      "172 -> one hundred sixty f ee  \n",
      "173 -> one hundred sixen y ee  \n",
      "174 -> one hundred siventy ee  \n",
      "175 -> one hundred siventy  e  [T]\n",
      "176 -> one hundred siventy  e  \n",
      "177 -> one hundred siventy  e  [T]\n",
      "178 -> one hundred siventy  e  \n",
      "179 -> one hundred sivent   e  \n",
      "180 -> one hundred sigeny   e  [T]\n",
      "181 -> one hundred sigety   e  [T]\n",
      "182 -> one hundred sighty   e  [T]\n",
      "183 -> one hundred sighty   e  \n",
      "184 -> one hundred eighty  ne  [T]\n",
      "185 -> one hundred eighty  ne  \n",
      "186 -> one hundred eighty tne  \n",
      "187 -> one hundred eighty tne  \n",
      "188 -> one hundred eighty tne  \n",
      "189 -> one hundred eighty tne  [T]\n",
      "190 -> one hundred eighty tne  \n",
      "191 -> one hundred eighty tne  [T]\n",
      "192 -> one hundred eighty tnr  [T]\n",
      "193 -> one hundred eighty tnre  [T]\n",
      "194 -> one hundred eighty tire  \n",
      "195 -> one hundred eighty tire  \n",
      "196 -> one hundred eighty tire  \n",
      "197 -> one hundred eighty tire  \n",
      "198 -> one hundred eighty tire  \n",
      "199 -> one hundred eighty tire  \n",
      "Correct 0 of 200  =  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 200, 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2words(label):\n",
    "    s = ''\n",
    "    for r in label:\n",
    "        s+=codes[int(r)]\n",
    "        #print(i,'->',s)\n",
    "    return s.strip()    \n",
    "    \n",
    "def check_model(verbose=0,show_training=1):\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(not show_training and i in trainSamples): continue\n",
    "        train=''\n",
    "        if i in trainSamples: train='[T]'\n",
    "        txt = label2words(res[i])\n",
    "        txt_correct = getWords(i)\n",
    "        ok=''\n",
    "        if(txt==txt_correct): \n",
    "            correct+=1\n",
    "            ok = \"[ok]\"\n",
    "        if(verbose==1):\n",
    "            print(i,'->',txt, ok,train)\n",
    "    if verbose==0:\n",
    "        for i in range(10):        \n",
    "            x = random.randrange(DATASET_SIZE)\n",
    "            print(x,'->',label2words(res[x]))    \n",
    "    print('Correct',correct,'of',len(pred),' = ',(correct/len(pred)))\n",
    "    return correct,len(pred),(correct/len(pred))\n",
    "check_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_number2words.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=188\n",
    "x = model.predict(np.array([input]))\n",
    "v = np.argmax(x,axis=2)\n",
    "#print(v.shape)\n",
    "print(label2words(v.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
