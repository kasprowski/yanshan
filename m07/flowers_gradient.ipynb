{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,202,609\n",
      "Trainable params: 4,202,539\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(64,64,3)))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\",input_shape=(64,64,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# We do not compile the model now!\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3670  samples\n",
      "classes {'dandelion', 'tulips', 'sunflowers', 'daisy', 'roses'}\n",
      "Labels shape (3670, 5)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "def load_img(indir):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for class_dir in os.listdir(indir):\n",
    "        the_class = class_dir\n",
    "        for file in os.listdir(indir+'/'+class_dir):\n",
    "            if file.endswith('jpg'):\n",
    "                image = cv2.imread(\"{}/{}/{}\".format(indir,class_dir,file))\n",
    "                #image = preprocess_input(image)\n",
    "                image = cv2.resize(image, (64,64))\n",
    "                samples.append(image)\n",
    "                labels.append(the_class)\n",
    "    samples = np.array(samples)\n",
    "    labels = np.array(labels)\n",
    "    return samples,labels\n",
    "samples, labels = load_img('flower_photos')\n",
    "print('loaded',len(samples),' samples')\n",
    "print('classes',set(labels))\n",
    "\n",
    "samples = samples / 255\n",
    "# one-hot labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(\"Labels shape\",labels.shape)\n",
    "labels = labels.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels,random_state=42)\n",
    "testSamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.05\n",
    "#                                , decay=0.01    ## when decay is used the learning rate decreases!\n",
    "#                               )\n",
    "opt = tf.keras.optimizers.Adam(0.0001)\n",
    "@tf.function\n",
    "def step(tsamples, tlabels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tsamples)\n",
    "        loss = categorical_crossentropy(tlabels,predictions)\n",
    "    #print(\"loss\",loss.numpy().mean())\n",
    "    # Calculate gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "step_no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== STEP  0\n",
      "[[  0  97   0   0  83]\n",
      " [  0 146   0   0  68]\n",
      " [  0  78   0   0  89]\n",
      " [  0  96   0   0  74]\n",
      " [  0  90   0   0  97]]\n",
      "Accuracy: 0.26 time 4.460725545883179\n",
      "Train accuracy: 0.28\n",
      "=========== STEP  1\n",
      "[[  0 133   0   1  46]\n",
      " [  0 180   0   3  31]\n",
      " [  0  92   0   1  74]\n",
      " [  0 106   0  12  52]\n",
      " [  0 109   0   2  76]]\n",
      "Accuracy: 0.29 time 3.790700912475586\n",
      "Train accuracy: 0.32\n",
      "=========== STEP  2\n",
      "[[  5  88   0  34  53]\n",
      " [  2 113   1  69  29]\n",
      " [  0  39   1  61  66]\n",
      " [  1  18   0 118  33]\n",
      " [  2  23   0  80  82]]\n",
      "Accuracy: 0.35 time 4.198116302490234\n",
      "Train accuracy: 0.39\n",
      "=========== STEP  3\n",
      "[[ 69  28   0  30  53]\n",
      " [ 42  71   1  65  35]\n",
      " [ 33  11   1  48  74]\n",
      " [  7   9   0 113  41]\n",
      " [ 21   9   0  72  85]]\n",
      "Accuracy: 0.37 time 4.112987279891968\n",
      "Train accuracy: 0.40\n",
      "=========== STEP  4\n",
      "[[ 95  27   0  11  47]\n",
      " [ 57  79   0  32  46]\n",
      " [ 41  14   1  22  89]\n",
      " [ 16  12   0  95  47]\n",
      " [ 35   9   0  34 109]]\n",
      "Accuracy: 0.41 time 4.234241247177124\n",
      "Train accuracy: 0.43\n",
      "=========== STEP  5\n",
      "[[ 46  84   0   6  44]\n",
      " [ 17 138   0  19  40]\n",
      " [ 21  40   1  16  89]\n",
      " [  7  32   0  83  48]\n",
      " [ 14  30   0  24 119]]\n",
      "Accuracy: 0.42 time 4.447722673416138\n",
      "Train accuracy: 0.45\n",
      "=========== STEP  6\n",
      "[[ 18 118   0   4  40]\n",
      " [  3 161   0  15  35]\n",
      " [  7  65   1  13  81]\n",
      " [  1  42   0  83  44]\n",
      " [  5  46   0  25 111]]\n",
      "Accuracy: 0.41 time 4.3559863567352295\n",
      "Train accuracy: 0.44\n",
      "=========== STEP  7\n",
      "[[ 11 109   0   7  53]\n",
      " [  3 150   0  20  41]\n",
      " [  7  52   2  17  89]\n",
      " [  1  35   0  90  44]\n",
      " [  4  37   0  28 118]]\n",
      "Accuracy: 0.40 time 4.328024387359619\n",
      "Train accuracy: 0.45\n",
      "=========== STEP  8\n",
      "[[ 23  92   1   8  56]\n",
      " [  4 139   0  26  45]\n",
      " [  8  41   3  18  97]\n",
      " [  2  23   0  96  49]\n",
      " [  7  23   2  29 126]]\n",
      "Accuracy: 0.42 time 4.205765247344971\n",
      "Train accuracy: 0.46\n",
      "=========== STEP  9\n",
      "[[ 49  71   1   9  50]\n",
      " [ 15 130   0  31  38]\n",
      " [ 22  34   6  19  86]\n",
      " [  5  22   0 104  39]\n",
      " [ 10  22   5  33 117]]\n",
      "Accuracy: 0.44 time 4.394568920135498\n",
      "Train accuracy: 0.47\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "for i in range(EPOCHS):\n",
    "    print('=========== STEP ',step_no)\n",
    "    step_no+=1\n",
    "    start = time.time()  \n",
    "    step(trainSamples,trainLabels)\n",
    "    end = time.time()\n",
    "    testResults = model.predict(testSamples)\n",
    "    print(confusion_matrix(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "    #print(classification_report(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "    accuracy = accuracy_score(testLabels.argmax(axis=1), testResults.argmax(axis=1))\n",
    "    print(f'Accuracy: {accuracy:.2f} time',(end - start))\n",
    "    trainResults = model.predict(trainSamples)\n",
    "    trainAccuracy = accuracy_score(trainLabels.argmax(axis=1), trainResults.argmax(axis=1))\n",
    "    print(f'Train accuracy: {trainAccuracy:.2f}')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
