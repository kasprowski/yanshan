{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2806,
     "status": "ok",
     "timestamp": 1611911484582,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "Ysiaxy0zzgvh"
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape, Conv2DTranspose, UpSampling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1611911489408,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "JKTEP7nSzgvy"
   },
   "outputs": [],
   "source": [
    "noise_dim = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1611913231056,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "E4TknOlYzgv0"
   },
   "outputs": [],
   "source": [
    "# creating the dataset of real images\n",
    "size = 32\n",
    "\n",
    "def create_images_vert(num):\n",
    "    samples = []\n",
    "    for i in range(num):\n",
    "        sample = np.zeros((size,size,1))\n",
    "        for _ in range(10):\n",
    "            x0 = random.randrange(5,size-5)\n",
    "            sample = cv2.line(sample,(x0,0),(x0,size-1),(255,255,255),1)\n",
    "        #sample = cv2.GaussianBlur(sample,ksize=(5,5),sigmaX=100,sigmaY=100)\n",
    "        #sample = np.expand_dims(sample,axis=2)\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def create_images_diag(num):\n",
    "    samples = []\n",
    "    for i in range(num):\n",
    "        sample = np.zeros((size,size,1))\n",
    "        for _ in range(3):\n",
    "            x0 = random.randrange(-size/2,size/2)\n",
    "            sample = cv2.line(sample,(x0,0),(x0+32,32),(255,255,255),2)\n",
    "        sample = cv2.GaussianBlur(sample,ksize=(5,5),sigmaX=100,sigmaY=100)\n",
    "        sample = np.expand_dims(sample,axis=2)\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def load_images(dir):\n",
    "    samples = []\n",
    "    for image_file in os.listdir(dir):\n",
    "        if image_file.endswith(\"jpg\"):\n",
    "            sample = cv2.imread(f\"{dir}/{image_file}\")\n",
    "            sample = cv2.resize(sample, (32,32))\n",
    "            sample = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\n",
    "            sample = np.expand_dims(sample,axis=2)\n",
    "            samples.append(sample)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1611914100374,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "TXoUT5pFzgv2",
    "outputId": "5ad00149-6b0e-4afb-a974-dad2bf8f3358"
   },
   "outputs": [],
   "source": [
    "#samples = create_images_diag(1000)\n",
    "#samples = create_images_vert(1000)\n",
    "samples = load_images('signs')\n",
    "samples = np.array(samples)\n",
    "samples = samples/255\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(samples[i][:,:,0],cmap='gray')\n",
    "    #plt.title(labels[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1611913298185,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "ptK_SpGAzgv9",
    "outputId": "f3651430-9f70-4602-bd77-467f1779ff73"
   },
   "outputs": [],
   "source": [
    "# Generator gets a noise vector of size noise_dim and generates an image of size (32 x 32 x 1)\n",
    "# Our aim: we want the image to be as similar to real images (generated above) as possible\n",
    "\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8*8*256, use_bias=False, input_shape=(noise_dim,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', use_bias=False)) \n",
    "    \n",
    "    #model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    #model.add(Dropout(0.3))\n",
    "    # output: 8 x 8 x 128\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation=\"nearest\"))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
    "    #model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    #model.add(Dropout(0.3))\n",
    "    # output: 16 x 16 x 64\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation=\"nearest\"))\n",
    "    model.add(Conv2D(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='sigmoid'))\n",
    "    #model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    #model.add(Conv2DTranspose(1, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    # output: 32 x 32 x 1 (our image)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1611913302368,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "hh_nX-DMzgv_",
    "outputId": "6c5b2227-3922-49e1-cfcd-fcafaee4b727"
   },
   "outputs": [],
   "source": [
    "# Discriminator gets image of size (32 x 32 x 1) and decides if it is real or fake\n",
    "# The result of the discriminator is used by generator to improve 'faking'\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 1]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #model.add(Dense(1))\n",
    "    # output: one number 0-fake, 1-real\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns randomly choosen n samples\n",
    "\n",
    "def sample_from_dataset(n,samples):\n",
    "    prev_numbers = []\n",
    "    new_samples = []\n",
    "    while len(new_samples)<n:\n",
    "        number = random.randrange(len(samples))\n",
    "        if number in prev_numbers: continue\n",
    "        prev_numbers.append(number)\n",
    "        new_samples.append(samples[number])\n",
    "    new_samples = np.array(new_samples,dtype=float)    \n",
    "\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1611913319251,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "thDAgGKbzgwB"
   },
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "def calc_ok(vct):\n",
    "    ok = 0\n",
    "    for x in vct: \n",
    "        if x>=0.5: \n",
    "            ok+=1 \n",
    "    return ok\n",
    "\n",
    "# The training step\n",
    "\n",
    "history = []\n",
    "##@tf.function\n",
    "def do_step(images):\n",
    "    batch_size = len(images)\n",
    "    images = np.array(images)\n",
    "    # create random noise for generator\n",
    "    input_noise = randn(batch_size * noise_dim)\n",
    "    input_noise = input_noise.reshape(batch_size, noise_dim)\n",
    "    input_noise = tf.convert_to_tensor(input_noise)\n",
    "    #noise = tf.random.normal([batch_size, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # generate fake image using noise\n",
    "        generated_images = generator(input_noise, training=True)\n",
    "        # evaluate fake images\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        fake_acc = (batch_size-calc_ok(fake_output))/batch_size\n",
    "        # generator want all images to be accepted (output=1)!\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        \n",
    "        # evaluate real images\n",
    "        real_output = discriminator(images, training=True)\n",
    "        real_acc = calc_ok(real_output)/batch_size\n",
    "        # discriminator wants to classify all real images as 1 and fake images as 0\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        disc_loss = (real_loss + fake_loss)/2 # sum up both losses\n",
    "\n",
    "    # calculate how to change generator to minimze its loss\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # step 4. calculate the gradient of the losses\n",
    "    # calculate how to change discriminator to minimze its loss\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # update weights for both networks\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) # step 5. Apply the optimizers and update weights\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    print(\"Epoch\",epoch,'g_loss=',gen_loss.numpy(),'d_loss=',disc_loss.numpy(),\"real_acc=\",real_acc,\"fake_acc=\",fake_acc)\n",
    "    history.append([gen_loss.numpy(),disc_loss.numpy(),real_acc,fake_acc])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IzfTO1NYzgwC"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # take some random samples\n",
    "    new_samples = sample_from_dataset(50,samples)\n",
    "    # perform one training step (epoch)\n",
    "    do_step(new_samples)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # show one real image and some fake images generated by generator using noise seed\n",
    "        #display.clear_output(wait=True)\n",
    "        num_examples_to_generate = 6\n",
    "        seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "        predictions = generator(seed, training=False)\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        r = random.randrange(len(samples))\n",
    "        plt.subplot(1, num_examples_to_generate+1, 1)\n",
    "        plt.imshow(samples[r, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(1, num_examples_to_generate+1, i+2)\n",
    "            #plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1611914196310,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "ObWRoFr8kEVy",
    "outputId": "425ebbf0-6966-4b35-e8f7-1eb4a0ed582c"
   },
   "outputs": [],
   "source": [
    "nph = np.array(history)\r\n",
    "\r\n",
    "plt.plot(nph[:,0], label='g-loss')\r\n",
    "plt.plot(nph[:,1], label='d-loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1611873385416,
     "user": {
      "displayName": "Paweł Kasprowski",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gid3j9YiV-A8q1cbwE_iu5-ZeO_Iy_eWmftCVBF=s64",
      "userId": "04465335559857235485"
     },
     "user_tz": -60
    },
    "id": "1zqSqBR0xass",
    "outputId": "cb4ff185-c053-4627-95ce-022f6623bd9d"
   },
   "outputs": [],
   "source": [
    "nph = np.array(history)\r\n",
    "\r\n",
    "plt.plot(nph[:,2], label='acc-real')\r\n",
    "plt.plot(nph[:,3], label='acc-fake')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMMF1TpS7WJP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan3.ipynb",
   "provenance": [
    {
     "file_id": "1WyIHIOLiZVhkgNmWeLhNl-_C1FJMABmY",
     "timestamp": 1611867870938
    },
    {
     "file_id": "1xZD1vSjIygVakySI8U4UUw-0OLq_8rIR",
     "timestamp": 1611856253043
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
