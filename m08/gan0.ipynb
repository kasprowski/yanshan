{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SQcktQWvgF9"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape, Conv2DTranspose\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaMWUx8bvgF_"
   },
   "outputs": [],
   "source": [
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roU40h9GvgF_",
    "outputId": "07dba61e-a526-4897-828e-1404876409fb"
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu', input_dim=noise_dim))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    return model\n",
    "generator = make_generator_model()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZhQCuiVvgGA",
    "outputId": "4c6f9fb6-2881-4200-f91b-34304e7839af"
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation='relu',input_dim=2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBWlHfB5vgGB"
   },
   "outputs": [],
   "source": [
    "# Optimizers and loss function\n",
    "generator_optimizer = tf.keras.optimizers.Adam()\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr9l-3fsvgGB"
   },
   "outputs": [],
   "source": [
    "# Generator of real points\n",
    "import random\n",
    "import math\n",
    "def generate_real_points(n):\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        x = random.random()*7-(7/2)\n",
    "        #y = x #\n",
    "        y = math.sin(x)\n",
    "        points.append((x,y))\n",
    "    points = np.array(points)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jcre1MGRvgGB"
   },
   "outputs": [],
   "source": [
    "# One step (epoch) of training\n",
    "def do_step(batch_size):\n",
    "    real_points = generate_real_points(batch_size)\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # generate fake points uning noise\n",
    "        generated_points = generator(noise, training=True) \n",
    "        # check real and fake points with discriminator\n",
    "        real_output = discriminator(real_points, training=True) \n",
    "        fake_output = discriminator(generated_points, training=True)\n",
    "        # discriminator loss - based on the number of wrong classification\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        disc_loss = (real_loss + fake_loss)/2 # avg of both losses\n",
    "        # generator loss - based of the number of fake points recognized by discriminator\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    # calculate gradients\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # apply gradients and update weights\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization - generates 100 example real points and 100 example fake points and shows the plot\n",
    "def show_results():\n",
    "  print(\"Epoch\",epoch,f\"generator loss={gl:.3f},discriminator loss={dl:.3f}\")\n",
    "  num_examples_to_generate = 100\n",
    "        \n",
    "  seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "  fake_points = generator(seed, training=False)\n",
    "  plt.scatter(fake_points[:,0],fake_points[:,1] , label='fake')\n",
    "\n",
    "  real_points = generate_real_points(num_examples_to_generate)\n",
    "  plt.scatter(real_points[:,0],real_points[:,1], label='real')\n",
    "  plt.legend()\n",
    "  \n",
    "  # red cross over each point classified as fake by the discriminator\n",
    "  fake_prediction = discriminator.predict(fake_points)\n",
    "  num_true_neg = 0\n",
    "  for i in range(num_examples_to_generate):\n",
    "    if fake_prediction[i]<0.5:\n",
    "      plt.scatter(fake_points[i,0],fake_points[i,1],marker='.',color='red')\n",
    "      num_true_neg += 1 \n",
    "\n",
    "  real_prediction = discriminator.predict(real_points)\n",
    "  num_false_neg = 0\n",
    "  for i in range(num_examples_to_generate):\n",
    "    if real_prediction[i]<0.5:\n",
    "      plt.scatter(real_points[i,0],real_points[i,1],marker='.',color='red')\n",
    "      num_false_neg += 1\n",
    "  accuracy_real = (num_examples_to_generate-num_false_neg)/num_examples_to_generate\n",
    "  accuracy_fake = (num_examples_to_generate-num_true_neg)/num_examples_to_generate\n",
    "  # Accuracy of the discriminator\n",
    "  print(\"Accuracy real\",accuracy_real,\"accuracy fake\",accuracy_fake)\n",
    "  plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MH0LiRtMvgGC",
    "outputId": "7ef8f7c0-74ab-4797-c055-db451477f325"
   },
   "outputs": [],
   "source": [
    "# Main loop - run steps and visualize for every 100 epochs\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    gl,dl = do_step(150)\n",
    "    if epoch % 100 == 0:\n",
    "       show_results()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the generator\n",
    "num_examples_to_generate = 100\n",
    "    \n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "fake_points = generator(seed, training=False)\n",
    "plt.scatter(fake_points[:,0],fake_points[:,1] , label='fake')\n",
    "plt.legend()\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [(x,y) for x in np.linspace(-4,4,100) for y in np.linspace(-4,4,100)]\n",
    "vals = np.array(vals)\n",
    "preds = discriminator.predict(vals)\n",
    "plt.scatter(vals[:,0],vals[:,1] , c=preds[:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan0_ok.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
